

# Reading the dataset into R
BF_orig_data <- read.csv("C:/Personal/Fall 2018/Statistical Models and Methods for Business Analysis/SMMBA_Final Project/Black Friday/BlackFriday.csv")

# Checking data types of all columns in the dataset
str(BF_orig_data)

# Converting few integer columns into factor variables
BF_orig_data$User_ID <- as.factor(BF_orig_data$User_ID)
BF_orig_data$Occupation <- as.factor(BF_orig_data$Occupation)
BF_orig_data$Marital_Status <- as.factor(BF_orig_data$Marital_Status)
BF_orig_data$Product_Category_1_ <- as.factor(BF_orig_data$Product_Category_1_)
BF_orig_data$Product_Category_2_ <- as.factor(BF_orig_data$Product_Category_2_)
BF_orig_data$Product_Category_3_ <- as.factor(BF_orig_data$Product_Category_3_)

# Renaming purchase column in the dataset
colnames(BF_orig_data)[12] <- "Dollar_Purchase"

# Confirming data types of all columns
str(BF_orig_data)


# ---------------------------- MISSING VALUE TREATMENT ----------------------------

# We are replacing the missing values in our dataset with the mode of variables

# Creating a function for calculating mode while making sure we exclude NAs for calculating mode
getmode <- function(v) {
  uniqv <- na.omit(unique(v))
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

BF_orig_data$Product_Category_2_[is.na(BF_orig_data$Product_Category_2_)] <- getmode(BF_orig_data$Product_Category_2_)
BF_orig_data$Product_Category_3_[is.na(BF_orig_data$Product_Category_3_)] <- getmode(BF_orig_data$Product_Category_3_)

# Checking if any column has NAs before we proceed ahead with the data
apply(BF_orig_data, 2, function(x) any(is.na(x)))


# ---------------------------- VARIABLE TRANSFORMATION ----------------------------

# Now we will be converting each categorical column into various binary columns based on the values which they hold
BF_gender <- model.matrix(~BF_orig_data$Gender -1, data=BF_orig_data)
BF_age <- model.matrix(~BF_orig_data$Age -1, data=BF_orig_data)
BF_occupation <- model.matrix(~BF_orig_data$Occupation -1, data=BF_orig_data)
BF_city_category <- model.matrix(~BF_orig_data$City_Category -1, data=BF_orig_data)
BF_stay_in_curr_city <- model.matrix(~BF_orig_data$Stay_In_Current_City_Years -1, data=BF_orig_data)
BF_marr_status <- model.matrix(~BF_orig_data$Marital_Status -1, data=BF_orig_data)
BF_prod_cat_1 <- model.matrix(~BF_orig_data$Product_Category_1_ -1, data=BF_orig_data)
BF_prod_cat_2 <- model.matrix(~BF_orig_data$Product_Category_2_ -1, data=BF_orig_data)
BF_prod_cat_3 <- model.matrix(~BF_orig_data$Product_Category_3_ -1, data=BF_orig_data)

# Making sure that no column created above has row sum more than 1
max(rowSums(BF_gender))
max(rowSums(BF_age))
max(rowSums(BF_occupation))
max(rowSums(BF_city_category))
max(rowSums(BF_stay_in_curr_city))
max(rowSums(BF_marr_status))
max(rowSums(BF_prod_cat_1))
max(rowSums(BF_prod_cat_2))
max(rowSums(BF_prod_cat_3))

# Getting the remaining columns from the original data apart from the above transformed ones
BF_user_prod <- BF_orig_data[c("User_ID","Product_ID")]
BF_purchase <- BF_orig_data[c("Dollar_Purchase")]

# Appending all the columns with 
BF_model_data <- cbind(BF_user_prod,BF_gender,BF_age,BF_occupation,BF_city_category,BF_city_category,BF_stay_in_curr_city,BF_marr_status,
                       BF_prod_cat_1,BF_prod_cat_2,BF_prod_cat_3,BF_purchase)


write.table(BF_model_data, file="C:/Personal/Fall 2018/Statistical Models and Methods for Business Analysis/SMMBA_Final Project/Black Friday/model_data.csv",sep=",",row.names=F)

# ---------------------------- MODELLING EXERCISE ----------------------------

# Building a correlation matrix
cor <- as.data.frame(cor(as.matrix(BF_model_data[,96]), as.matrix(BF_model_data[,-c(1:2)])))
write.table(cor, file="C:/Personal/Fall 2018/Statistical Models and Methods for Business Analysis/SMMBA_Final Project/Black Friday/corr_with_purchase.csv",sep=",",row.names=F)

# Building a basic Linear Regression Model considering only the top 5 +ve and -ve correlated variables

#Reading the same data again to take care of the $ sign, which were being auto-generated by R
BF_model_data <- read.csv("C:/Personal/Fall 2018/Statistical Models and Methods for Business Analysis/SMMBA_Final Project/Black Friday/model_data.csv")

BF_LM <- lm(Dollar_Purchase ~ BF_orig_data_Product_Category_1_16+BF_orig_data_Product_Category_1_10+BF_orig_data_Product_Category_1_6+
              BF_orig_data_Product_Category_2_2+BF_orig_data_Product_Category_1_1+BF_orig_data_Product_Category_1_8+
              BF_orig_data_Product_Category_1_11+BF_orig_data_Product_Category_1_4+BF_orig_data_Product_Category_3_16+
              BF_orig_data_Product_Category_1_5
            , data=BF_model_data)
summary(BF_LM)


# Building Decision Tree
library(rpart)
set.seed(123)
BF_DT_data <- read.csv("C:/Personal/Fall 2018/Statistical Models and Methods for Business Analysis/SMMBA_Final Project/Black Friday/BlackFriday.csv")

# Checking data types of all columns in the dataset
str(BF_DT_data)

# Converting few integer columns into factor variables
BF_DT_data$User_ID <- as.factor(BF_DT_data$User_ID)
BF_DT_data$Occupation <- as.factor(BF_DT_data$Occupation)
BF_DT_data$Marital_Status <- as.factor(BF_DT_data$Marital_Status)
BF_DT_data$Product_Category_1_ <- as.factor(BF_DT_data$Product_Category_1_)
BF_DT_data$Product_Category_2_ <- as.factor(BF_DT_data$Product_Category_2_)
BF_DT_data$Product_Category_3_ <- as.factor(BF_DT_data$Product_Category_3_)

str(BF_DT_data)

getmode <- function(v) {
  uniqv <- na.omit(unique(v))
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

BF_DT_data$Product_Category_2_[is.na(BF_DT_data$Product_Category_2_)] <- getmode(BF_DT_data$Product_Category_2_)
BF_DT_data$Product_Category_3_[is.na(BF_DT_data$Product_Category_3_)] <- getmode(BF_DT_data$Product_Category_3_)

#splitting the data into training and test(validation) sets - 80% for training, rest for validation
nr=nrow(BF_DT_data)
trnIndex = sample(1:nr, size = round(0.7*nr), replace=FALSE) #get a random 80%sample of row-indices
mdTrn=BF_DT_data[trnIndex,]   #training data with the randomly selected row-indices
mdTst = BF_DT_data[-trnIndex,]  #test data with the other row-indices

# Developing a tree on the training data
set.seed(123)
rpModel1=rpart(Purchase.Bucket ~ ., data=mdTrn[,-c(1:2,12)], method="class",  parms = list(split = 'information'), 
               control=rpart.control(minsplit = 25,cp = 0.0001,maxdepth = 10))
#summary(rpModel1)

#Obtain the model's predictions, confusion table and accuracy on the training data
predTrn=predict(rpModel1, mdTrn, type='class')
table(pred = predTrn, true=mdTrn$Purchase.Bucket)
mean(predTrn==mdTrn$Purchase.Bucket)


#For confussion table statistics
cm <- table(pred=predict(rpModel1,mdTst, type="class"), true=mdTst$Purchase.Bucket)
n = sum(cm) # number of instances
diag = diag(cm) # number of correctly classified instances per class 
rowsums = apply(cm, 2, sum) # number of instances per class
colsums = apply(cm, 1, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted classes
accuracy = sum(diag) / n 
accuracy
precision = diag / colsums 
precision
recall = diag / rowsums 
recall
f1 = 2 * precision * recall / (precision + recall) 
f1

# Plotting the best obtained model
plot(rpModel1, uniform=TRUE,  main="Decision Tree for Black Friday")
text(rpModel1, use.n=TRUE, all=TRUE, cex=.7)
rpart.plot::prp(rpModel1, type=2, extra=1)
summary(rpModel1)

